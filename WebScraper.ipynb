{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScrape.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMectT61FHsFoAM0bVfNY5u"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4617zZbwrveF"
      },
      "source": [
        "# web scraper for tickers\n",
        "\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as web\n",
        "import bs4 as bs\n",
        "import requests\n",
        "import os\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzhcTduPsF1s"
      },
      "source": [
        "# Scrape wikipedia table for nasdaq stocks\n",
        "\n",
        "def scrape_func():\n",
        "\n",
        "  response = requests.get('https://en.wikipedia.org/wiki/FTSE_100_Index')         # variable\n",
        "  soup = bs.BeautifulSoup(response.text)\n",
        "  table = soup.find('table', {'class': 'wikitable sortable'}, id='constituents')  # variable\n",
        "  tickers = []\n",
        "  tickers_dot = []\n",
        "  for row in table.findAll('tr')[1:]:                                             # variable ('.' if, is for silly formatting on wiki, where tickers have periods)\n",
        "    ticker = row.findAll('td')[1].text\n",
        "    if '.' in ticker:\n",
        "      tickers_dot.append(ticker)\n",
        "    else:                \n",
        "      tickers.append(ticker + '.L')\n",
        "\n",
        "  with open('Nasdaq-100tickers.pickle', 'wb') as f:                               # file name\n",
        "    pickle.dump(tickers, f)\n",
        "\n",
        "  return tickers\n",
        "\n",
        "scrape_func()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm2bhbolsMkT"
      },
      "source": [
        "# with that list, now get data from yahoo, download as csvs all in the same directory\n",
        "# if you get throttled for too many requests, add time.sleep(x) to allow server to recover\n",
        "\n",
        "def yh_get_data(reload_tickers=False):\n",
        "  \n",
        "  if reload_tickers:\n",
        "    tickers = scrape_func()\n",
        "    tickers = ['BTC', 'ETH', 'BNB', 'XRP', 'DOT', 'ADA', 'UNI']\n",
        "\n",
        "  else:\n",
        "    with open('Nasdaq-100tickers.pickle', 'rb') as f:                             # file name\n",
        "      tickers = pickle.load(f)\n",
        "\n",
        "  if not os.path.exists('stock_dfs'):\n",
        "    os.makedirs('stock_dfs')\n",
        "\n",
        "  start = dt.datetime(2020, 6, 1)\n",
        "  end = dt.datetime(2020, 6, 30)\n",
        "\n",
        "  for ticker in tickers:\n",
        "    print(ticker)\n",
        "    if not os.path.exists('/content/stock_dfs/{}.csv'.format(ticker)):            # file location (path)\n",
        "      df = web.DataReader(ticker, 'yahoo', start=start, end=end)                  # source of financial info\n",
        "      df.to_csv('/content/stock_dfs/{}.csv'.format(ticker))                       # file location (path)\n",
        "    else:\n",
        "      print('Already have {}'.format(ticker))\n",
        "\n",
        "yh_get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFXr7Y0qTon1"
      },
      "source": [
        "# If you already have a ticker lisk, just compile all csv into here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU_bP0EpzOPW"
      },
      "source": [
        "# combining all csv data for ['Adj Close'] into one dataframe\n",
        "\n",
        "def compile_data():\n",
        "  with open('Nasdaq-100tickers.pickle', 'rb') as f:                               # file name\n",
        "    tickers = pickle.load(f)\n",
        "\n",
        "  compiled_df = pd.DataFrame()\n",
        "\n",
        "  # iterate through these tickers, dropping all columns and renaming adj close as ticker\n",
        "  for count, ticker in enumerate(tickers):\n",
        "    df = pd.read_csv('/content/stock_dfs/{}.csv'.format(ticker))\n",
        "    df.set_index('Date', inplace = True)\n",
        "\n",
        "    df.rename(columns = {'Adj Close' : ticker}, inplace = True)\n",
        "    df.drop(['Open', 'High', 'Low', 'Close', 'Volume'], 1, inplace = True)\n",
        "\n",
        "    if compiled_df.empty:\n",
        "      compiled_df = df\n",
        "    else: \n",
        "      compiled_df = compiled_df.join(df, how='outer')\n",
        "\n",
        "    # basically a loading bar\n",
        "    if count % 10 == 0:\n",
        "      print(count)\n",
        "\n",
        "  print(compiled_df.head(10))\n",
        "  compiled_df.to_csv('/content/stock_dfs/nasdaq_joined_closes.csv')\n",
        "\n",
        "compile_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR3pCFM96Tpo"
      },
      "source": [
        "# Visualise correlation data as a heatmap\n",
        "\n",
        "plt.style.use('Solarize_Light2')\n",
        "\n",
        "def visualise_data():\n",
        "  df = pd.read_csv('/content/stock_dfs/FTSE_joined_closes.csv')\n",
        "  \n",
        "  # Correlation matrix for any scraped data\n",
        "  df_corr = df.corr()\n",
        "  data = df_corr.values\n",
        "\n",
        "  fig = plt.figure(figsize=(24, 12))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  # plot a correlation heatmap\n",
        "  heatmap = ax.pcolor(data, cmap=plt.cm.RdYlGn)\n",
        "  fig.colorbar(heatmap)\n",
        "  ax.set_xticks(np.arange(data.shape[0]), minor=False)\n",
        "  ax.set_yticks(np.arange(data.shape[1]), minor=False)\n",
        "  ax.invert_yaxis()\n",
        "  ax.xaxis.tick_top()\n",
        "\n",
        "  # Note, data.shape[x], and column/ row labels only really matter with asymmetric data\n",
        "  colummn_labels = df_corr.columns\n",
        "  row_labels = df_corr.index\n",
        "\n",
        "  ax.set_xticklabels(colummn_labels)\n",
        "  ax.set_yticklabels(row_labels)\n",
        "  plt.xticks(rotation=90)\n",
        "  heatmap.set_clim(-1, 1)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "visualise_data()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}